>> Coming up next, I'm really looking forward to it. I hope you are too. It's called the Singularity: Classical ballet and digital ethics. So I'm gonna hand it over to Genevieve and Alex.

GENEVIEVE: Hi! It's a little weird to talk about classical ballet and computing education, and the digital ethics includes biodigital ethics.  Before we get into this, I'm gonna explain why I'm doing this. So it makes a little more sense for you. This is me and all the things I do in a beautiful infographic. So apart from running Ready Salted Code, a not for profit computing education LLC, I come from the classroom teaching GCSE and A level computing, computer science, game design, into now teaching new teachers and developing creative computing. So when I was teaching,there was only me as the female in the classroom. I wanted to find a way of getting more girls interested in computer science, as well as being a little more creative and not just doing Python and the magic 8 ball that we all have to teach these days. I went to dancing school when I was very little, and that's my passion. Along with the Dragon 32 and Ice Castles. That was my favorite game.  But unfortunately I have a condition called spinal synostosis. I had multiple spinal fusions. So that's where my passion for classical ballet comes from. And I now use classical ballet as a medium for teaching computer science theory. I've produced three ballets, along with Alex. And also our choreographer, Camilla. And that's a fluoroscope of my spinal implant. I use classical ballet because of how it aligns with computer science theory. If you don't know anything about classical ballet, it's very, very strict and rigid, like a programming language. I'll half demo here. You have positions of your feet, which also correspond to positions of your arms. And there are only certain ways you can combine them to be correct motifs. If you think about how you might position your foot, the certain steps that you're allowed to do are very rigid and very strict. The same you would get with Python or JavaScript or whatever language you want to use. I'm very language-agnostic. And that's why we use it, as a way to show that the language can be algorithmically created for the ballet. Our ballets use secondary school students that are not computer science students, nor are they professional dancers. I don't dance. I just choreograph some of it. And enjoy it. Because it's kind of cool.

So it was a really, really good way to create different elements that you could use for teaching computer science theory. Not only can you manifest or use classical ballet as the narration and the data as the storytelling -- we can also create workshops and resources for teachers, for all the wearables that we do. We did projection mapping. And Alex also built our server. So if you want to grab some JSON data from a Kinect, we've got a brilliant one. You type in how many keyframes you want, and it'll slurp up the data. I need easy stuff. I'm a mediocre programmer. The very first ballet we did coincided with the introduction of the computing curriculum. It included five elements: Building in binary, computational thinking, debugging, big data, and algorithms. We used projection mapping, live weather data, and also lots of wearables. So that was a way we could teach students Arduinos. And it's a really, really good way -- electronics are a really good way to introduce coding as well. So there's a couple of... We used torches, and this is a picture of the Kinect, when we were doing binary tree structures, just to show you what it looks like. It doesn't have to look like stick men. It can be really beautiful.

And what's interesting for me is I know that that's Kate. I can tell how she dance. So that was quite interesting from our perspective. So we did a lot of different things. So the very top one with the circles is 100 years of rain data. The one next to it is signal processing, where the dancers are using different motifs to represent the signal processing algorithms. The one at the bottom is the Kinect stick figure. That's for debugging, so that's why you have all these trace and errors in it. And the one at the very bottom represents networks and viruses. We use a lot of wearable technology in the ballets. These initially were -- electronics, wearables, and point shoes are not friends. I'm just saying. They don't like each other at all. So every single performance, they always break. Perfect rehearsals. Absolutely no problem. One little test, go live, all the connections snap. Literally every performance? Yeah.

>> Something goes wrong.

GENEVIEVE: So we've kind of needing to find a new way. This is using the AdaFruit Gemma... Not the Gemma. The Flora. NeoPixels. And the little inside bit that looks like a bit of black plastic is Velostat. It's pressure-sensitive plastic. Looks a bit like a bin bag, but it's pressure-sensitive plastic. That's how we use that as a trigger in the point shoes, so we could minimize risk to the actual dancers. Our latest ballet is called pain byte. That was released last October. And that was about chronic pain and biomedical engineering. So the dancers represented pain signals. We had some dancers representing the biomedical engineering technology, my implant, and then we went through and did what the pain pathway system looks like and how we can modify it, using art features to create imagery. So the audience could understand the hidden nature of chronic pain.

We also created a VR experience. And then turned that into workshops. So this is the technologies that we used. And so the Daydream Alex built using lots of different stuff. And the Codespaces is an education platform for building VR experiences using Codespaces blocks. Blockly and JavaScript. And it's really, really easy to use. I just had 60 kids build it. Up in Sheffield. Having fun. It just works with the Google Cardboard, but it's a good way to introduce coding to students, before you might want to move on to build VR experiences in Blender or Unity. It's nice to do lots of different things. So our fourth ballet that we were producing is called the Singularity. And this is about... So from a computer science perspective, we want to take about latency, communication, and augmentation of the human body. So that's why we're boldly going into space. So how can we communicate when we travel into space or go to colonize? And what will we need to do in order to facilitate the human body to do that? Do we need to augment it?

And then this is where the challenge comes in. If we are going to do that, what are the ethical considerations that we need to look at? So should we augment people, or should we just send robots? What are the ethical decision of who owns that data, if you have a biomedical implant? So that's one of the things we wanted to think about with the students, when we're teaching the digital ethics. Is: What data are you sharing when you have your fingerprint to get your lunch? Or book your library book? Which is fine. It's perfectly acceptable. But they need to understand what's going on. So the reason why we're using... We're gonna be using the Emotiv headset, which Alex has got on, and that captures your brainwave data. Alex is gonna model the Emotiv headset, everybody. A little cat walk for everyone. And so this has a five-point connection. The Emotiv do another one called the Epoch, which has 10 points.

It's obviously nowhere near as good as what a neuroscientist would use. But obviously we need one that you can use when you're dancing. It's very noisy, the signal. It's not brilliant. But it's better than nothing. This is just an animation of kind of what brainwave signals might look like, in a pretty way. So when you get the Emotiv headset, it gives you an app like this, that you can use, or a couple of pieces of different software to download -- either Mac or Windows. And you can get the raw data out. Unfortunately, I don't have that one. Because that's too expensive. As everything. Everything's too expensive. But they're brilliant. They're really helpful as well, the staff. And then I've got a little video that I recorded of my brain yesterday. Panicking about this workshop. This talk, sorry. So you can see it gives you like a little kind of animation of how your brain might light up. It's obviously not an accurate representation of the signals coming from the brain. We want to use this particular data to create biofeedback. So this data that's coming out -- it's in a format called OSC. You can use that with many different things. So including things like Sonic Pi, so you could control the music using the brainwave data. I don't really know how well that would sound. But it might be okay. So that's one of the things that we're looking at. We want to create our own music using all of our biodata. For the classical ballet. So that we can also minimize the sort of copyright of the music that we're using.

We also want to show how students can code their own music and create their own music. All with the understanding of: This is someone's hidden brain data! What does that mean, to show this data to other people? What are the ethical considerations when you're working with that? So I'm gonna hand you over to Alex, because Alex built the Scratch plugin that we're gonna be using in the workshop later. How you can use the OSC data from the Emotiv headset to control Scratch. So I'll hand you over. Thank you.

>> Hello! So I'm Alex. I've been Genevieve's technical provider or whatever it's called for ages. And I'm a software developer by trade. So for me, this is a really cool opportunity to do stuff that is not like regular programming. Programming for performance is nothing like day job programming. With a day job, you're gonna have to support it in six months' time. You're hopefully gonna be supporting it in two years' time, and still have a job. Whereas with a performance, it's like... Develop, develop, develop... Gone! So there's a lot of hacking. There's a lot of just do it with whatever weird technology you can find. Fortunately for this project, we saw it had an OSC interface to the brainwaves, and I was like... I've done OSC before. OSC is really simple! It was invented for... It's open sound control. If you want to Google it. It was invented for replacing MIDI, which was rubbish. Actually, it's great, but... It wasn't detailed enough!

So it's basically a way of passing strings and numbers fast across a network. And in this case, the strings and numbers are bits of brainwave information! So you'll get... There's lots of facial recognition stuff as well. I don't know... Like, quite how it knows whether I'm smiling or not, but it does! So that's kind of cool. And winking and blinking. But you can also send mental commands. So you can train it to pull and push and things. So we're picking those things up. And sending them to a little server that's part of our project. And then... Next slide. Yeah! It goes into Scratch. And you can have this data, and you can use it to move things around with your mind in Scratch. It gives you control over... Well, typically that cat. Is it called Scratch? It's called Scratch, isn't it? Yeah. And where was I going with that? Um... So it's about making it simple. It's about giving you control over it.

Scratch has had three iterations. It's currently in beta for its third. Which is a big relief to me, because I didn't want to ever program in Flash ever again. So it's now available in HTML. And that's much nicer! So we downloaded that. Forked it. And just added in some bits, so that was to connect our module to the rest of Scratch. And it's just very... The OSC comes in. It's just numbers and strings. And our little server just pokes it into Scratch, and then it's just like writing a web page. It's just a bit of JavaScript that connects to an API and says: What's this number? And it says: Five! So really, really simple. But... It's very, very nice that Scratch has enabled this. And made it simple, and it's just like... The green bar, the orange bar. This is a thing for moving the cat whenever you will it to go... I think left? Left. Yes. It makes it walk. Just an example. You can do anything. You can visualize your thoughts. Obviously as Genevieve was saying, we use the cheap version of the license, so we don't get all the really detailed data of like... This is going boom and this is going boom. We've kind of got... You know, what you saw in the previous slide.

But it's still a lot to show how you can use your brain, and how you can use that data yourself. As somebody who's maybe not particularly familiar with computers.

GENEVIEVE: Yeah, so Scratch -- some of it is not fully working. So when you come to the workshop, do be prepared for it to be a little bit broken. I'm just preparing myself, basically. Yeah. And then the other thing that we're going to have a try with is Sonic Pi. So if any of you are interested in coding music, that's a really, really good platform to do that. And this is only just started, because Scratch 3 was only released in August. So it's only been released to other developers and it's still in beta, and there's still a few things... So you can't save any of these files that you create. Because they are just live, running on a beta server. Just so you know that when you go online. But it's much better now that it's HTML5 and not Flash anymore. Obviously we're sharing the Scratch one here because we want to introduce digital ethics to students. But for us, when we're using it in the ballet, we'll probably be controlling -- using the OSC data to control the stage lights, but using an aggregate score of the wearers, so that nobody's data is shown or nobody's data is available to other people. So we won't record anyone's data at all. Only my own and probably Alex's.

In order to use the headset as well you officially have to be 16. But obviously if there are some parents in the workshop and they sign a waiver, they can put it on. But we won't record anything. You might want to try it. It's incredibly uncomfortable. It's really tight on your head and you get divots on your head. But that's quite useful when you're dancing, because obviously you move around a lot. Even in ballet, even if you're not jumping around, there's still quite a lot of head movements and stuff. And it does stay on if you do a pirouette or a spin, if you don't know what one of those are. That was really important, for us to find a way to encode the dancers' data while they're doing it. And then use them for the visualizations, the wearables, and any of the projections that we might do. We've only just started on this. We haven't formulated how the ballet will finally be, but it will most likely be sometime in September to October, when we do the live performance.

So I just have some links that you might be interested in. We have all of our resources in GitHub. So for all of our ballets, all of the wearable code, the Kinect server code, whatever code we've used, they're all in GitHub.

>> Do not judge my programming!

GENEVIEVE: Do not judge mine either. Oh my God. And also, it's so messy. Also, the ballets are on data-driven dance. So the three that are recorded... I say three. The last one isn't quite up yet. And if you are interested in the Emotiv headset -- there are other headsets that you can use. It was just this one was... Had enough points on it to get enough data. Whereas a lot of the others only have one or two, that are within my price budget. So it was $300 for one. And when you're doing... Is there a classical ballet for one performer? As Alex was saying, from start to end on a single performance is round about 20,000 pounds. Eight dancers, eight sets of point shoes, eight sets of costumes, a billion and one NeoPixels. I'm surprised I don't have any on me. I'm normally just walking around with hundreds of lights. And obviously the development costs of all the software that we use. The hiring and stuff. So it's important that... That's why it's takes a lot of time. Obviously you have to get the funding for that. So ballet is quite an expensive thing to do, if you're interested in that. But mainly to do the costumes and things like that. That's where it comes from. But yeah. So I hope you found the talk really interesting. And if you... We're all good. I hope you enjoyed it!

(applause)

>> So I was gonna say... We've got ten minutes. If any of you want to ask questions. But before we do that, you mentioned that you're gonna be doing a workshop later. Do you know when and where that is?

GENEVIEVE: So it's 6:30 in workshop 2.

>> There you go. So do we have any questions from the floor? No? One there? And one there. I'll come back to you. Can you stick your hand up again? There you go.

>> Hi there! Can you support multiplayer-type experiences with this sort of headset as well? Or is it solely one headset per computer?

>> So the OSC protocol is completely network agnostic. So even if you only have one plugged into one computer, you could certainly then take that data and glue loads of it together.

>> Any more for any more? One here?

>> Could you demo the thing with Scratch?

>> Yeah, that's what we're doing in the workshop later on. Yeah. We just can't do it now, because it's a different laptop.

>> What do you think is the most interesting thing you've found from using the headsets on the dancers?

>> So we haven't used it on the dancers yet. Because I only just got it. But I used it on myself, and I have had ballet lessons. And I think the thing I found... Was actually the other dancers -- so I go to a dance class which has -- everyone is over 60 during it. So the other ladies were watching my brainwave data, and they found it absolutely fascinating, how you can see what you're... Because we were learning new stuff. So you could see what you were doing, and how it kind of affected the visualization of what's going on in your head. Just the fact that you could see it. And that was one of the things that we were talking about. The fact that you can see this -- there is an ethical issue of it. Because, like, can you imagine in the future if, like, they use your brainwaves to decide what job you're gonna have? Or whatever? You know, that kind of thing. So yeah.

>> One over there. Oh, sorry. Yeah. That's right. Where are my manners?

>> Why did you choose to do the brainwave stuff thingy? Whatever?

GENEVIEVE: Why did I choose brainwaves? A little bit came from the previous ballet, where we had chronic pain and the hidden nature of chronic pain. The fact that you don't see that I'm in chronic pain. So we were trying to expose it. And then we were trying to find different ways that you could expose other data that might help you understand ethical decisions and things like that. Thank you!

>> Thank you.

>> There was one over there. Yes.

>> So are you aiming to get data from the way that dancers dance in any case, or to give them something they can consciously affect and control?

GENEVIEVE: Hm. When we work with our dancers as well... So they're part of the whole development process. So we kind of want to look at -- when you're learning the classical ballet, what do the brainwaves look like? And then kind of once you know it, is there a difference, and can we affect the wearables or the lights or the projections? Basically. So they may want to be interested in how it does the element that you were talking about, the kind of... The kind of learning feedback system. But we wanted to look at it as a sort of biofeedback maybe. But we haven't quite got there yet. We're still deciding. But that's a brilliant idea. Thank you.

>> Oh, one over there.

>> How accurate do you find the brainwave?

GENEVIEVE: Hm. I'm not a neuroscientist. But I'm assuming they're not that accurate. Are there any neuroscientists in the room? There is one? Ben could probably help us. They're not...

>> I've never had the pleasure of actually playing with it.

GENEVIEVE: You can play with it later.

>> Excellent. I'll see later.

GENEVIEVE: So you can get the raw data off of it, but it does require you paying for another piece of software. And obviously one of the things we try to do is do free and Open Source stuff. This is kind of limited to where we try to put things out into a classical learning situation. But what I'll do is I'll maybe do a comparison with a perfect EEG headset and do a post on it, so we can see the comparison between the datasets. There is another headset which is more accurate, but again... That's double the price. Or triple the price. So yeah.

>> One over here. And I think we'll make that the last one.

>> Hi. Really good talk. Thank you very much. So my question is: Have you considered... So putting possibly the ethical part aside, or coming up with a way to aggregate it, so you can't look at an individual... Putting the headset on audience members or the people watching or experiencing the ballet? Because I think that would be a very interesting thing to add into the performance.

GENEVIEVE: That's what we're going to do, but when we're talking about the recording -- that's only on us externally. We will share... The only data that we'll share publicly is mine, because that's fine. But we're looking to use the audience's aggregated feedback to control some element of the live performance. Obviously that's just gonna go terribly wrong, isn't it? But, you know, it'll be fabulous. But yeah. Brilliant idea, thank you.

>> Thank you.

>> Okay. Thank you. One last round of applause for Genevieve and Alex. And let's get another plug in for their workshop. 6:30 in workshop 2. Is that right? Yes. Go to it. So I just have a couple of housekeeping announcements to make. Number one is: If you are the kind of people that like making...



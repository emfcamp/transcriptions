
>> Okay. Pardon me while a do a quick microphone calibration test. This is the voice of DOOM! All right. Okay. Hello. My name is Alec. And I am old! So I would like to share a couple of perspectives from back before the internet became the world wide web. Because I think it might be useful to the builder and maker community... I think it might be useful to folk who are trying to innovate in the application space. And so there are two things that I would like to share with you. Which I think were key to the success and development of the early internet. Firstly, in the beginning, all of the internet's communications were end to end. End to end is a bit like peer-to-peer. Except that there are only two of you.

So it's a bit like a rope. If you've got a net and it's only got two ends, it's actually a rope. If you had an internet mesh -- this is a map of the internet from 1977, so it's a little earlier than the target dates that I'm kind of describing, talking about. But it serves for illustrative purposes. And you had Alice in Stanford, on a PDP11 on the left hand side and Bob at NYU on the right hand side, who's also on a PDP11, and if they wanted to communicate, the software that they would use to communicate would be talking directly between the two of them. A route would be forged between Alice and Bob and the bits and bytes would go back and forth directly between them. There would be no firewalls, which were blocking the communication or making it hard for Alice and Bob to do this. There would be no intermediaries on which Alice and Bob would have to rendezvous in order to communicate. Instead, they would be talking directly between each other. There would be no men in the middle. There would be no impediment to their direct communication. And it would actually work.

It was quite fantabulous to be able to do this. Let's not, though, dwell on the internet security in that era. Frankly, we didn't do it too well back then. It was kind of rough. But it was a safer, sweeter, more innocent age. Secondly, one of the more important aspects of making a successful tool in this era: The command line names tended to be a bit embarrassing. Something like, for instance, "finger". Especially if you used it with the standard UNIX systems administrator, this would be very road to say in Australia, I am told. The finger program was the user information search database program. You could see who was logged in. Or you could inquire whether a user on a system was currently logged in, and you could also get a little bit of extra information about them. Finger protocol, incidentally, ran on TCP port 79. And if you add one to port 79, you get port 80. This is not really a coincidence. There's a reason for this.

Because on the finger command, if you created a little bit of information, if you created a file called .plan in your home directory, and another file called .project, when someone fingered you... There's that word again... You would have this information pop up on the remote display. The person would get this information that you had created yourself. It becomes content which you share over a network, and it's a personal expression opportunity. It's a way to communicate what you are working on. And this led to a sort of proto-blogging, as we would now understand it. Any time after the mid-1990s. But 10, 15 years earlier. You could put quite a lot of information into a plan file. A little example here on a 4.3 BSD emulator I ran up, just so I could get these screenshots. They're actual legit things. But if you go back in history, John Carmack, the guy who wrote Doom, had an enormous plan file, which was essentially his daily blog of what bugs he had found and what bugs he had fixed and what challenges he was facing and new features, and so forth.

And you accessed his blog via this finger command. You could even do prototypical -- what we now have as Flash animations. Like this thing. It turns out that if you are connecting to the internet over a 9600-baud serial modem, you have a fixed bit rate, and so by sending printable ASCII characters and carriage returns and linefeeds, you can actually get animations like this. I'll leave this running for a second. This is plain ASCII and carriage return and linefeeds and a bunch of stuff like that. And if you want to see how that finishes... There's a link to the video in the pinned tweet on my Twitter page. It's the reply to the current top pinned tweet.

You can also find out more information about plan files and some of the stuff about them in the Hacker's Dictionary, and if you go digging for this kind of information, this kind of content. So I want to make the glib assertion on which this entire talk is based that end to end communication aids innovation in distributed computing. It aids and eases information sharing if you do it right. And it helped make the internet that we know today. So the talk, though, is: Why and how to use onion networking. Normally I would be talking to an audience of people who are privacy activists about onion networking. And I would say something like: If you have a community or an audience who face censorship, if access to real news or real content is hampered, if there's a risk of fake government websites or fake non-government websites lying about the state of the universe... Or if there are political repercussions or social repercussions for accessing websites about gender and sexuality, and so forth, or if you need additional privacy assurance and trust, you might want to use onion networking.

But I want to look at the other aspect for today. Which is: If you are building a disintermediated or distributed -- again, an E2E tool, something like Onion Share, a file tool going point to point over an onion network, which you are temporarily connected to for as long as necessary to transfer the file. Or BriarApp, which is a social space, kind of blogging/bulletin board tool, based around the same sorts of distributed technologies that usenet used to be based on, but layered over TOR and several other transport technologies as well. Or if you are an IoT home automation fan and you are worried about someone spying on your home webcam because occasionally you walk around nude, or something like that... TOR and onion networking is a great tool to ensure the privacy and integrity of your own communications, point to point, and be certain that it isn't going through or temporarily cached on the file servers of Facebook or Google or Twitter or whomever or even just some sort of AWS cloud thing which eventually gets popped by a bunch of hacker weenies.

What is the adoption of onion networking? Am I talking about some tiny little annoying tool which nobody's ever going to use? No! Facebook has an onion site. The New York Times has an onion site. Cloudflare has recently added HTTP over onion, and a new feature which is opportunistic onions, where any Cloudflare customer can add onion networking to their website for turbocharging their website experience, for people who connect to it over TOR. It's not the Dark Web anymore, although it is what used to be called the Dark Web. It is the technology for giving additional transport layer security to HTTP. What is the social value of onions, if you're going to deploy it? The reason that Facebook deployed it was that it gave greater assurance if you're connecting over TOR that you weren't being man in the middled by one of the exit nodes, exit relays. Instead you're connecting directly into Facebook. It gave you greater privacy, greater availability over TOR, because exit nodes tend to be a bit congested and a bit flaky, and you have fewer digital footprints as well. You're making a pure end to end connection over TOR.

The tech value of onion networking comes in the second half of the presentation. Just to fill a few gaps here, because frequently people ask these questions afterwards: Are there clients for other platforms? Yes, Mac, Linux, Windows all use TOR, or you can run up the TOR browser and go through that. Android likewise. I don't have a slide for the next statement, but in terms of complexity, I would put it about on par with tunneling traffic over SSH. If you've ever used an SSH connection to go from your local machine to remote machine, and drilled a hole backwards or forwards to connect to port 80 over it, it's about that level of effort. You're meddling with a few configuration files and you have to have the process running, but otherwise the data just goes happily backwards and forwards under your control. This is a static file of me playing video over the Times website on my Android phone to prove that it could be done. I would have more than one video in this presentation but it just seemed unnecessary.

This is my TOR development environment to prove that the resource requirements are not onerous. The little Raspberry Pi bottom left, a configuration with six others in a webfarm. This is all freely available, and I'll talk about that a little bit later. So I've mentioned the word onion and onion networking quite a bit. What is it? .onion is the top level domain name for the onion namespace. What do I mean? A namespace is an address and what it means or what it looks like. So you've got IPV4 namespace, which is 192.168.1.1. Strings of digits with dots in the middle. You've got IPV6, which is hexadecimal, with lots of random colons arbitrarily spaced in it. DNS addresses are all www.foo.com nowadays, and onion addresses looks like some random gibberish with .onion on the end of it. How do they work? You type them into a browser and connect them to a computer. That's pretty much it. There's a slight tweak with IPV6 that you have to add square brackets, because of syntactic issues which Tim Berners-Lee forgot to think about.

However, there's a cute twist. Because .onion is unusual. Under the bonnet, it's actually a raw network address. It looks like www.foo.com.  www.something.onion. However, it's actually a string of binary digits that mean something to a network stack. It also means, because of this neat duplicated... It's not really a duplication. Because of this quirk, you can use subdomains. This wouldn't make sense for IPV4. You could not have www.192.168.1.1. That would not mean anything sensible to any web browser.  Again, because of a goof that Tim Berners-Lee didn't think about. However, www.Facebookcorewwwi.onion is still meaningful to HTTP. It still connects you to that binary onion address but the www bit gets transported in the host header because it looks sufficiently DNSish, and everybody is happy.  The addresses are treated equitably, and so you get standard www web sort of behavior even with an onion address. How do you choose onion addresses? Essentially you mine them. It's a little bit like BitCoin. You throw random coin tosses using a special bit of software until you get one which, when written down on a piece of paper, would look intelligible-ish to a human being. How does it work?

Again, to my metaphor of SSH, you have a config file and say on port 22 I want everybody to be redirected to my home port, 22. Or port 443 or whatever it might be. At the local end, if you want to connect to that, you do some magic in your SSH config file or whatever it might be. If you're doing web over onion, how do you serve content? One, you set up a dedicated web server. You could just sort of hard code a TOR daemon to talk to localhost 443 and run an Apache daemon on your local machine and everything would be fine. Perhaps if you want to have the same content as your blog or something, which is connected to the internet, perhaps you might mirror the content that you've got on your blog, or alternately, you could have an onion-aware CMS. Many CMSes understand that I'm simultaneously foo.com, foo.co.uk, foo.co.jp. And foo.fr. And return content that's pertinent for each of those top-level domains. With .onion, you would just add an extra one into the mix and treat and respond to it in a consistent fashion.

Oops. Or you implement an onion shim. Which is a piece of software which dynamically rewrites the traffic between your onion domain and address to your .com address, and so HTTP requests outbound get rewritten in terms of the onion addresses that are inbound, and the ones that are -- responses coming inbound have come from the onion addresses. This all makes sense a bit later. So you could, like concrete examples here... Have a dedicated onion service for, for instance, SecureDrop. It's a whistle blowing tool. It's beneficial to have some degree of anonymity and some degree of extra privacy. Facebook uses the onion aware CMS hack, where Facebook.com and the equivalent onion address are both understood by the stack and responded to in consistent manners, and the New York Times has a shim which rewrites all the content for their nytimes.com site to be in terms of onion addresses so you can browse the NY Times site using the onion address, which is under their control. Implementation tips. It's nice to be consistent. This slide is probably a little too verbose for this particular presentation.

If you're doing HTTP, there are some special certificates you will need. This is getting easier to get ahold of. But again, it's entirely solvable. This is how all of these sites, which I've listed beforehand, have set up their onion addresses. So that their browsers understand how they work. The technology behind this? Well... I suppose this is where we kind of deep dive into onion networking a touch. And networking in general. And I apologize. I'm gonna use some words which come straight out of 1985. Firstly, if you hack around with ethernet and IP, you will know about ARP and MAC addresses and things like that. And so you've got... Your MAC address is your physical hardware address and the IP packets get sent to it, if they're intended for you. Onion addresses work like this, and the reason I've got these two slides is so I can go back and forth and back and forth and back and forth and just try to underline the point that this is essentially the same idea.

That actually, TCP/IP is the data link layer of onion space. You can actually do the seven-layer model in terms of TCP being pushed down to being the LLC layer for onions. And onion space is end to end. It's a very flat network which doesn't know about or care about firewalls. So you can communicate between Alice and Bob once more, with no intermediaries, no rendezvous points, no everything. You are disintermediated. You also beneficially don't need firewalls so much. Firewalls come from an age when ports on computers, processes on computers, listened promiscuously to the network interface and would accept any traffic that was inbound. With onion networking, you essentially publish what services you would like people to connect to. This is closer to the X25 paradigms of many, many years ago.

So you could say: I want port 44422 to be my inbound SSH port, and you literally put that out on the internet, in the TOR cloud, and people will be able to connect to it, but they don't get access to anything else that's running on your machine, whatever the port numbers might be, whatever the processes might be listening. You only put out in a consent-based way, effectively, what you are permitting people to connect to. This is a lot closer to where we were back in 1985, when it was possible to finger someone across the breadth of the entire internet. Onionspace is circuit-switched. This is mostly put up here to explain why it still runs fast. Because the internet, as we know, mostly is packet-switched. Everybody hopefully has come across packet switching. Your data is broken down into little postcards that get flung across the internet bit by bit. In this, a pipe, a series of tubes, is built between Alice and Bob, and the data goes back and forth along this tube. It sounds great. Of course, the downside is this is on top of TCP and has a lot of cryptography, so it's a lot slower, but not as slow as it could be. It works perfectly fine for streaming video. It's adequate. You'll notice there's a little loss in performance, but it does work pretty good.

Next is rendezvous, not client server. We are dreadfully so used to the client-server paradigm. We must use Google.com, must use Facebook.com, whatever the DNS points us at, as the IP address to connect to, to send mail to this person. Instead... Your server and your client both can sit in little enclaves behind NAT firewalls, where no one from the outside can talk to them. Where they can sit in their own little protected shell, and they publish out to what's called the DHT, to the hidden service directory, as it's called. They publish out what port numbers and addresses and so on they wish to be contacted on, and the clients can connect to them there. By a process of negotiation and rendezvous on the pink blob. These slides are all up also on Slideshare, so if you want any of them, they can be got later. Also from the pinned post on my Twitter feed.

The point being here is that your servers can sit in these protected, safe little enclaves, safe from DDoS attacks and hackers and all sorts of other stuff, and the only services you expose are the services you choose to expose. And that can be connected to. Rendezvous sounds complicated. It sounds like it's not client-server. It sounds different. But TOR goes to extensive great lengths to hide the fact that it's not client-server. You still wind up connecting to Facebookcorewwwi.onion. But it goes through a rendezvous process to get there. It's a little bit like... Where Alice and Bob normally might send messages to each other on Facebook -- we're going to meet on Facebook. Hello, Bob. Hello, Alice. The messages use Facebook as a rendezvous point. With onion networking, the setup is done via rendezvous, but it's shifted from giving Facebook control and the copy of the conversation to just the initial call setup, you might say, and everything else goes just between the two of them. They have all these features. Redundancy, transience, they migrate globally. They're highly DDoS resistant, and essentially operate on a DNS round robin principle, which is how Facebook and the New York Times do their load balancing between multiple servers.

Also they have self-authentication. If you can connect, if you can actually type the address in, and you manage to connect to the thing that is the address you typed in, you're definitely talking to the thing you intended to. There's no opportunity for DNS hijacking, for fake addresses, and so forth. The features which would be provided by IPsec like authentication headers and encapsulating security payloads are all done by TOR for free. And finally, internet separation, which is... Actually, TOR doesn't really care about the internet. It's an over-the-top metanetwork. Which means that if some country is routing traffic around, in order to try and disrupt the internet, TOR will route around it, and not really care. You will still definitely be talking to the... I make that 7 minutes, but... Hm.

You will still definitely be talking to the site that you intended to. So if you remember one thing from this talk, please, TOR treats censorship as damage and routes around it. It is quite literally the raison d'etre of TOR. This is what we were supposed to be doing with the internet. This is what John Gilmore said. The internet treats censorship as damage. We got lazy. We focused too much on doing things cheap and fast and putting things in the hands of big corporations, who are selling off big fat chunks of fiber, and maybe we missed some things. We missed some of the older essences that made the internet originally a useful tool, a great tool, for building and deploying software on. I think it's something we should reclaim, and I think onion networking is a good way to do it. There are downsides. It's a little bit slower. There occasionally are circuit drops. But Meh. Occasionally that happens too -- if your firewall crashes, you lose all the connections through it.

And secondly, you will be learning new stuff if you embrace TOR. But that's not a problem either. It's not an in-kernel network. You're not doing sockets and stuff like that. You'll be talking SOCKS5. Most people have proxies that can do that. You're meddling with configuration files in a slightly fiddly syntax format, but it's not worse than tunneling over SSH. TOR is an evolving target, but it's getting better all the time. And it has an awful lot of promise. I think it would be a really good thing for folks to be building tools on. I did an example -- middle of last year, I decided I was going to build an onion site for Wikipedia. The entire configuration file is that. Using the tool called EOTK, which is something I worked on for the NY Times and released. And you create a config file that looks a bit like this, and runs some magic stuff, a couple of commands to just build stuff and config things and so forth, and 10 minutes later, you actually have got an onion site for Wikipedia, so much so that it got covered in Vice and other magazines. Why do this? It was mostly a short-term example to prove the concept, but it was useful. Some folks decided: Hey, let's go troll this guy and DDoSed it and did other stuff to it. Turns out TOR is pretty good at stopping people DDoSing things. It's a fairly high barrier to entry for people who want to make your life difficult anyways, because that's what TOR is all about. But also, with a little bit of load balancing and a few rejection rules so you can get rid of all of the clearly spammy requests, a few hundreds or thousands requests per second didn't actually make the CPU spike on a quad-core Intel in some data center somewhere.

It was barely noticeable. It was just filling the log files at speed. That's a fixable problem. So... Why onion stuff? Because you can build apps and tools and devices which don't need to fret about NAT, which don't need holes drilled in firewalls, where you don't need to pay for some central server or AWS server -- however microscopic the price might be, you don't have to worry about your nude wanderings around whilst you've gotten out of the shower being stuck in some AWS server in a bucket and being raided by Russians or Koreans or Americans and being posted all over the internet. The data will go where you choose it to go. It will provide access and safety and security opportunities, assuredness for your communications, and it's fun. So... Oh, and actually... Whoops! Can I go back one? Yes, I can go back one. One little "and finally" thing... You can go so far as to password protect your network interfaces. If you are wandering around nude, do a little bit of TOR configuration magic and the network address will not even appear unless you know a special password in order to access it. Which is not something you could ever do with any kind of TCP or ethernet stack that I'm aware of.

So my name is Alec. I hope you've enjoyed this. The slides and the videos are up on my Twitter feed. Please go ahead and write some E2E tools and give them embarrassing names. Thank you!

(applause)

Apparently I will answer questions in the bar, or somewhere else afterwards. If I would like to.

>> Thank you, Alec Muffett. We still need volunteers. So if you would like to sign up, there's a volunteers link at the top of the main EMFCamp website. Thank you.


EMF 2018 Infrastructure Review by David Croft, Will Hargrave.
>> We're starting with a talk about the 2018 infrastructure review. 
>> Hello, everyone. We're here to tell you about the adventure we have had in the last year to build the infrastructure, the challenges we faced, and how you used it. The thing started from the site design. I will introduce Russ from the admin team who is responsible for it. 
>> I'm going to talk about the bit of over-engineered bits of technology we used to design and plan the festival. We signed the contract for the site almost a year ago, actually, I think. It seems like a really donning time ago, and had a couple of site visits where we camped for the weekend, and worked out where everything might go. It's exceedingly difficult with this site because everything has to be on something approximately flat. But, that's not many places around here, and it very importantly, the tents don't have to go on top of water mains, as we found out in 2016, and various other, like more practical things, like where do the roads go, how can we use the roads so that we don't have to rent in so much track way, and so on. This is one of our planning sheets we did in March that we drew in what we thought we had to do. This is our CAD plan with the layers turned on. So, it has like the underground service website the power, and the network, and the lighting, and ducts, and pipes, and all sorts. Trees, stumps. That is how the web map is generated. It's generated directly from that CAD plan. We have this increasingly sophisticated pipe line we can use to turn a CAD plan which is good for planning where things go, and making sure the tent is not too close to the track, or things like that, and also, then that turns it into a web map which I completely rewrote this we are to be vector and - it mostly works except in some people's weird browsers. Not my fault! There's a diagram of that, which used to be much more complicated but this is the kind of simplified new diagram which isn't quite as - and, yes, the docs are out of date, sorry. We got signs this year. I'm not sure why I'm talking about these. It is quite exciting. The council were, "You should have signs to tell people to slow down." I called the AA and told them to do some signs for us, and they were like, "Sure." It was the easiest supplier I had to deal with. I hope people found them helpful. I don't think we needed all of them, but they seemed to work pretty well. Then the day before we came on site, somebody delivered the bins, which was kind of them but they put them where we were going to put our initial logistics area so we then had to move about ten tons' worth of bins. They came out with a bin-washing machine which was exciting. But it was exciting! [Laughter]. Now I'm going to talk about our power infrastructure which I've been perhaps a little bit too much designed in involved in designing this time. It's a common theme with EMF, like, this doesn't work, doesn't away the work the wait we need it to, let's write a completely new system. So we have this computer-aided power design system which takes our main plan which I showed you before and converts it -- it works out if the plan is valid and the right things are plugged into the right people. The right panels, and so on - the right people! [Laughter]. Then it spits out lovely graphs, so this is, this is one third of our power this year. I can barely see that! I don't know how well it's coming out on the expensive projector. So that shows every single piece of distribution equipment, and the links between them, and how much voltage drop, and prospect ive fault volt current and those respective things we've been nerdy about in the last six months. Because the EMF power system is done entirely done by EMF rather than by an external company, we have to make sure we do the testing and validation of it. This is part of that. It tells you if the cabling is not big enough or various other things. It flags it all out in this huge diagram. And then of course, no plan survives contact with the real world. So we did put our power order in quite late. Our supplier are fantastic. They're one of my favourite suppliers, and I have a list of my favourite suppliers. And, they were like, "We're going to have to substitute a few things, and move these things around, we don't quite have enough of these, and we don't have enough those," and we ended up with this mess. That should say 119 distribution boards of more than 16 ambassador. Three generators, two of which world record-holder 200KvA and 800kVA or 800 Watts power capacity, like we didn't need the big generators and didn't order them. Sorry, you will have to have the vast 300kVA generators. Somebody went round just now and counted all of the people plugged in, and apparently, there's more than 400. I didn't verify that number. So this is the main supply off one of the generators. We have these juicy 400amp going away from those. That's a container full of the power distribution we have. Several tons of it. And we did a bit of aerial power rigging with heavy cable which was - it worked. A little bit wobbly. It didn't fall down, which is good. And, yes, there's a small ample of the 400 connections plugged in, and the fire extinguisher - safety first. In EMF 2016, we had a bit of a problem that we didn't tell you about. Over the weekend, we realised that we were getting really close to the wire with actual, and so we had to get Benny under this tele handler and get him to unscrew the fuel drain plug and siphon the fuel out of the tele handler into the generator. [Laughter]. [Applause]. So this time, we didn't want to do that. So we got some bigger actual tanks, much bigger. They all arrived, and they dropped them off. We were like gone and picked these up from another site, and they're all empty. This was last Tuesday. They just turned up with all this equipment, and the... are empty. We had to find somewhere to buy 6,000 litres of diesel, which is quite a lot of diesel, about five grand's worth. They couldn't come until Friday, actually, they came, and so we had to get another fuel tank to make do. That's what an empty fuel tank looks like in case you hadn't seen one before. That's what an empty tank generate internal fuel tank looks like on the left. Putting the lighting in was a bit of a challenge this time. It turns out this particular site is very, very hard. Usually we put the bits of metal in called put-logs holding the festoons up. We had way more festoon but we couldn't get these things into the ground where or they kept bending them, or the tele handler would tip over, or something like that. I don't know if one kilometre is the amount of installed lighting but for the first time we used LEDs rather than incandescent bulbs which lets you wire them into the longer strings. That's why it all looks "cool white". We did a bit of site lighting finally. Last year, I - last EMF, I volunteered myself to try and do some of this. I was way too busy. Begot a load of lights out. Some art net happened. We have a site-lighting team, and they've been doing some pretty stuff, and, next time, it will be even more pretty. They're using these off-the-shelf ethernet to art net to DMX nodes and a load of DMX cable, and the laptop. This got found somewhere. Did they try to stick it in the socket it was in the socket, I'm informed! Don't do that! They're not compatible. [Applause]. 
>> Hello, again. I'm David from the team, and I'm going to talk about ... link. You've been to EMF before, you will recall the first few events, we were running wireless point-to-point links. Fortunately, this - unfortunately, this time, it wasn't an option because there are many hills around here which basically are impossible, even if we had somewhere useful to go to, which we didn't. So planning for this actually began around about the time that we first came to I have the have the site in August last year. And we quickly realised we're going to have to get a circuit, a commercial provider and we're out of the site. What we wanted to do was make it really easy for the supplier to put it - built a cabinet right by the road, ran ducting for them right to the road, so all they have to do was ... connect up their duct to our duct, pull some fibre through. We were here in January digging in some very hard ground getting trenching in for the duct to the road, power to the cabinets, and sheep were in the field. The field was not a camping field at that time of year. As someone keeps asking for requests of sheep. We saw deer as well in the adjacent field. This is what we ended up with this this is how we left it. This is how we returned to it, covered in weeds later, a few weeks ago. In the meantime, the provider had come. [Off mic]. Excuse me, here's an example of just outside that cabinet, in fact,. You can see branching off to the left are two ducts for circuits that we used, one is [off mic]. Going off to the right which was hastily added last week, in fact,. Made - actually comes all the way up here to site, because what we discovered using ... fairly illegible documentation but actually walking through and actually looking at ... is that ... you would in theory be able to pull fibre all the way up. The back-up plan, same as usual ... here we are. This is about 1.2 kilometres of fibre. We rodded ... we pushed a stiff rope back through, pulled the rope back through again, all the way. On the right here is ... apparently we energised Team Cine to ... by the spool, unspooling solution. There we go. This was splicing in the back of a van down by the main gate. Where as our network operation centre which we got running fairly early. It was the staging point and the distribution point for taking the ... .  Our date centre, in 2012, we rented scout tents. It went pretty well except that it was hard to cool and kept gets bits of field in [off mic]. In 2014, we had a refrigerated shipping container, which was so great, it was so cold. It was too cold, you couldn't set the set point high enough to stop it constantly chilling, because the door was opening frequently, people going in and out, it produced a load of condensation blown over the switchers and serves which had to be covered in tarp. Cold, but side effects. 2016, we went for what the bar used which is a cool room, basically. We didn't realise at the time that the in-built chiller unit was mostly designed for keeping already cold things cold. Food and drinks rather than actually cooling enormous amounts of outputs from switches and servers. We did have to buy air con at last minute. This is assembly of the cool room, the data centre. The former location of the inadequate cooling unit has been replaced. Heady stuff - heavy stuff on the bottom, UPS, very heavy, and then left to right, we have the we have the wireless land controllers, [ ... you may have noticed there is no flat on this field. Bodges had to be put in certain points to stop the air conditioning from tipping over. Un like previous years, we only had one power feed. [Applause]. 
>> Thank you. I will talk about the actual stuff out in the fields. This diagram comes from the same CAD system used for power distribution. A lot of development there. Purple lines are the fibre that goes across the fields, so, from places ... the circles are 50 diameter circles ... rule of thumb, you don't really expect people to bring longer cables than that. Data ... flat and if you pay attention to where the purple lines go here, you will have noticed that these are all little islands. One of the big features of this field is that there are - infrastructure between several places that we could use for data where we didn't have to crossroads. Both cross ings are annoying to do. There is lots of traffic always, and advance, and stuff. You have to work with ... which are expensive, and this way, with lots of ... this is on the field, a lot of hassle in ... parking infrastructure here. Basically ly, these LEDs boxes with - for them, and, at this side, we would break out the copper fibres, and the rest would go on. So, from the core, we had a star network from the core. We would patch everything all the way through from the end of the field without having to have any ... all over the place. [Off mic]. This is how the network plan looked. This is the logical diagram. As you can see, everything is connected to the core switch, to the router, Eastnor. A non-native ... . And the couple of places, we didn't want to run ... and we had a ... cable ... and the bottom layer, you see diagram ... yeah, it's sideways, but ... this is the physical diagram which you can see is different and these are not switches but these are the ... so, for example, you can go from the left to the right of the diagram and follow the cable from one data cloud to another all across the field. No active women in between. Again, this is coming from a single source of truth which is really helpful when ... that've knows what ... what land needs to be where ... depending out what is where. This is one of those splice boxes through the field. On the right side, you see the multi-core fibres, the outdoor fibres underneath the ground. They're supplied into pig tails with ... and these end up on the pig tails that are then put into ... and all those cables go to the switches. The connector on the right, the uplink connects on the left go to the field, the coming into this, and we had two more of these. And the event is over, we roll up all the cabling inside. We put it back in the trench. I don't know, maybe in two years, we can ... don't have to do all the splice work. It shows all the foes quote from. Data cloud, for people who this was the first EMF, originally, I think invented by the Germans ... who looked because we don't want people to take them for what they ... this power going into it.  On top of that is an on light. Very useful, because, if you walk around the field, you can immediately know there is the nearest network access point. You can run your cables down it. And shoot  loose interconnection, the fire and flame animation, you know immediately there's an outage. From the inside, the cables coming in on the bottom, one going out. There's a switch in there. And this one, I took this picture on Friday afternoon, so not many people around I don't think we ever ran into a situation at this event where we needed to add a second switch. Reserved for our own stuff, GSM, base stations, and the access points. We had some ethernet switches. Most of the stuff that went wrong ... - stuff that went wrong: one of the challenges is is that  is that you start out, arrive on site and build out this temporary network because we need to be online. They're saying can we check our emails for production? So you build something temporary, and, as the events starts, you need to move from the ... final set-up. We had one device in one of those cabinets that ... to serve as a media converter, and we had to take it out, and, whenever we took it out, the normal - take over, because wasn't acceptable. This link had different suppliers, contact them all, have them all debug their little part of it, and, eventually, it turned out there was ... that was dropping all the ... indicating that it was all the traffic. This is why, in practice, IPv6 on day one before - final equipment there. We worked for two hours getting this switch on line through copper outlaying. We changed everything, the cabling, recrimped it. Let's not use the copper as a feed. This particular switch is 10-gig ports, and we put those in there, and normally this works. But, after we took them out, you can see that the lights, the green lights on the bottom row that are laid out, they are the link lights, so this switch current ly thinks that these ... on top of it. Yes, two hours. Going in graphs is a hobby that certain people took up, where, if you have a public graph, then, go down, ... but if you have significantly more capacity available than you have, use it. You have a place where you can send a lot - you can create a nice spike. Then you stop sending traffic, it goes down, and it's so fine and Dandy until you don't have much capacity, and you DDoS the campsite that way, which is what happened here. It was enough for everything we, please.  For all the traffic that people did, for it to go out, and all that, but just didn't really have much capacity to ... so, spend time and effort contacting, having identifying source destination, and we ended up having to take the port off line. Because that was the target of the DDos attack. The first one somewhere in Germany to do with ... please don't do that. It is annoying, and confuses everybody on the ... and ... . Finally, this wiring that you guys have here, luckily, somebody brought stickers, to notify us of the problem. Deployed, and through the UK, and I know that you guys like ... so the European mainland federation was - glad to help out. Of course, Europe being Europe, we also proposed a solution! [Laughter]. We will help you implement ... from now. [Applause]. 
>> This is the problem having a presentation with many teams to work on. Seamlessly someone will put in a ... . Wi-Fi ... so I will hand over now to AK who is going to talk about the Wi-Fi distribution.  
>> Wi-Fi, it's about putting up lots of access points, I guess this slight didn't come in too well. Okay. So, some of the photos are not on here, that are supposed to be on here. But, yes, we put up a lot of access points around 70 of them. On the left, you see a few of them when they're being staged when we were back in the Netherlands. On the left, you see an access point mounted to a fence, and, on the right, you see the access point up mountains on all the - so that is actually an indoor access point mounted into a plastic box that's used for water proofing it. That's a fairly cheap solution to use a cheaper indoor access point and on the top here, you see the GSM antenna, and one of the ArtNet lights. There is supposed to be on the photo on the right but we can't ... some statistics about the Wi-Fi material, so we had 72 access points deployed, all 82llc - 800 concurrent stations that were currently connected to the network, and in the course of this four - these four days, we've seen around almost 6,000 unique devices on the Wi-Fi network, and, actually, most of the devices connected to the network were actually on Wi-Fi, about 94 per cent of them. Only six per cent ... we also had a number of SSIDs - well, most of them were encrypted, and some were inencrypted, almost 0 per cent of you guys used the encrypted network, so that's good. 80 per cent of the stations were on 5 gig. I think the badges can't do 5 gigahertz, so they're taking down the percentage on 5 gigahertz. Of course, 5 gigahertz has more capacity than 2.4 gigahertz but also, here in the UK, they Ofcom opened up a little bit more spectrum, so they add ed 5  five more 5 gigahertz channels, so we could use 24 five 5 gig channels, so there's way more spectrum to play with around with on five gigs. Please use 5 gigahertz and ... . Yes, some more stats in this slide. You guys were able to actually use a random user name and password on the encrypted Wi-Fi but apparently almost none of you tried to to this, so it's EMF and anonymous, and - realms that are in this top then, anything going on. On the different operating systems we've seen on the network, Linux is our number one, so that is good. For some reason, there's Windows 98 there! [Laughter]. [Applause]. ... we also collect a lot more data about Wi-Fi network. We can look at how many clients are associated to the different, so one thing we can look at is how many clients are in a certain room, so we can use this data to see which presentations are popular, so apparently, the most popular talks were banned from encrypting and the making of the TiLDA MK4, and hackers was very popular yesterday. Side bar was crowded, and Milli ways was also ... . We have some other statistics. We have this 1 gig uplink which was saturated because - thanks for that. Next year, we have to hog more bandwidth. We've got to go for 10 gig or something. This is the - we see a couple of peaks there but that might not van genuine traffic. Last night, the temperatures were okay. The night before that, it was very, very cold, so you can see I think a 20-degree difference during the day and during the night, so, it you're looking at the temperatures of all the switches we have on site, I think, yes, probably 20 degrees difference between day and night, so that is what .... I think that's it for statistics. We're going to move on to video. [Applause]. 
>> As some of you may have noticed, we haven't done our usual thing of having a mediation level ... . This is mainly due to everyone being absolutely knackered by the time ... . But now, I will pass over to a team far more professional ... operations centre, pass you over to Martin. [Applause]. Hi, everybody from the C3voc from Germany. A few stats of our live streams. We had around 100 viewers at the peak, after 120. Most of the people that were watching the live steams which is like an adaptive stream technology, and devices mostly use HLS, and some devices watched ... . So our ticket tracker, overall, we recorded 11 events, 26 events were not recorded, those were either speakers that didn't want to be roared, or music and movie events that aren't being recorded. That's almost 62 hours of video being recorded by us, and most of the stuff is already online, and you can ... . [Applause]. So we also faced some challenges at EMF. First, those tents arrived late, and we had to do everything on Friday morning, and it was very stressful. But so, during the build up at the stage feed, there were some power outages which also didn't help. For the first time at this event, normally, we render our videos with an introduction at the beginning with a small video which introduces the speaker and what the talk is. The guys from EMF wanted it to be like a transparent lower third thing, so we had to build it in our pipeline, and work out, and so now, every video starts with a lower third which has to be fans which so it overlays the video. One talk had an emoji in its title which was a little bit challenging but everything worked, expect automatic intro generation. I had to fix that. It is already up on YouTube, and on our own platform, and everything worked. Actually, on this stage, one HDMI split remember was bricked by a Tesla Coil, so, on this stage, we have some problems with the video on the projector, but I think it is working now. We also really liked the Lucky Cat. You can try all the recordings up to now, and some are missing at media.ccc and on YouTube. [Applause]. 
>> So many of you already know, for the first time, at EMF, we have p the team were testing out their - fortunately, they have had to - unfortunately, they have had to leave early. We will be talking on their behalf, and he's also going to talk about the network he built. [Applause]  [Applause]. 
>> Thank you  my name's Sam. I've been involved in building the phone network. We have a common core. I work closely with Thomas and the DEC stuff. Thomas presentation I've seen once, so this is - might have slipped in there. First thing, really, as you see, one of the big things that event put in this year was self-service for registration, those who have been waiting for your DEC phone to get on line, had to be a manual process, one registration at a time. They put in a lot of work where you can register, so the DEC antennas were always in registration mode and say register to network and a default pin. That gave you a temporary allocation on the network with a really long number that wouldn't route anywhere, and then you could register your number in Guru and dial the activation code which then reprovisioned your phone. I think that worked well. It meant that number for GURU was not just for DECT but for GS M&S IPP, so you can SIPP-register a phone. I've been using my iPhone with an application on it. You had three different ways to access the same phone system. The same kind of principles we could expand, the unified experiences across the network, we had one phone system. Things they've learned for EMF. The capture, those of you who signed up early on in GURU found the capture significantly challenging, or everybody was a robot! There was a little git  bit of we will turn down the aggressiveness. It's most UX-type things in any web application. It added call groups as well. I don't know if fib found that, but if you had a number that would ring multiple extensioning, so if you wanted a number for your village that would ring six people's DECT phones in the village, you could register that. This is kind of what the IP architecture looks like. In terms of hardware, the servers were running on VMs built ahead of time and moved up to site. There was another telephony engine, Yate, a SIPP platform. There were a number of Yate instances handling for the network, so the DECT stuff gets converted into SIPP as well as GSM. We had a VoIP call server, and then we had the DECT antennas you see that on cloud, so they were running at a private VLAN across the site, so all the DECT antennas were switched into a specific port on the VLAN. The GSM over on the right there. Similar to the DECT antennas. The hardware for those, the GSM station is a Raspberry Pi and an SDR radio. We have a Raspberry Pi and an open VPN. The VS fires up an open VPN tunnel back into our VoIP call and then runs the GSM over there. What was really nice it meant I had one of these base stations plugged at home when I've been doing testing via the VPN. We didn't have to rely on a programme for that. So, just some management stuff over on the outside, and then you will see the - Nexmo gave us credit make the external calls to the traffic out, so it was routed out to them. We have the GSM servers up the top there. The core is the Osmocom stack. Those - the MSc, the BSC, the HMY, all running in one on that box. That has a SIPP interconnector. That came out over SIPP that way, and the GSM services was an asterisk box for doing hacks and tweets, and as much as s on there, and test numbers, and, generally, it gave me a box on there. . Those who found the inbound, there was a UK number that you could dial which would give you a dial tone, and then dial anything as if you were on site, so dial to especially on site, dial - you would just get a dial tone. This is what was on the network. We don't know how many GSM devices attached to the network. We know we had 1,900GSM-enabled devices at some point, but we don't have great stats on the traffic on there. That could be one location update or phones attempting - or people's phones that tried to register and been barred or something like that. 2 7 DECT phones. 70SIPP extensions. 33 people signed up for a personal SIPP number, personal GSM number. With the SIMs we gave you in the badges, they all had a number by was that 4-1234 number. You could use that number, which people who got their GSM did. You could reassign it to a personal number as well. The active calls going out to the real world, we have this problem I started after 4 am on Friday morning, is that? Through until sometime at 12 o'clock. Basically, someone hooked up one of their SIPP extensions to a server than a phone. And their SIPP server wasn't a protected server. Anyone who has put a SIPP server on the internet it takes 20 minutes before someone starts to poke you with attempts. They poked their server, they found it can make outbound calls via our server, and that burned through EUR1,000 calling credit to Serbia. I had to have an awkward conversation with our boss, that thousand euros of credit you gave me, I've kind of lost it! Can I have some more, please. Fortunately, he did. I checked the balance, and, actually, since we locked that connection down, and we've put in a few limits, from DECT and GSM, only used 60 euros of credit, legitimate calls. That was definitely some forward there. We - fraud there. We did only allow UK, Europe, and US prefixes nay which should have blocked out the obvious fraud destinations I kind of missed - maybe Serbia. That will go in my banned list for next time. This is an interesting thing from the DECT network. The DECT base stations need to synchronise with each other, so they need to be on a synchronised clock. We don't have this this on GSM which is why we don't have handover. The DECT can synchronise our other F-links between them. The lines, you will see the spots are where the DECT antennas are, and you can see the one down by the gate. There is one down at the DK by the gate there. They discover each other. Even a red link is a low-quality, a red, yellow, green quality links but these would keep them in synchronisation. They're sink knifing with their channels. A couple of plugs. The challenge of the event phone is they're trying to get more followers on Twitter, so clearly trying to break into social media. The GSM stuff, challenges we had, the time frame, getting it all bit, really, I was being pushed, you know, we were right up against it, and we were reliant on so many other bits of infrastructure that we got there. Deploying the BSBTSs in the real world. The stuff worked really well, and I have had stuff running on my desk at home for weeks. It turns out, when you start sticking it on a wooden pole in a field, some of the environmental things, so Thursday night was furiously spent soldering five-volt power lines. And, yes, man and woman power, I ended up doing nearly most of the GSM stuff myself with help from Thomas. A big shout to Yaga if she is here who helped putting up the base stations on Thursday, and then went round and put them down when I thought was a software problem and a hardware problem with, so can you get them down and put them up again? [Applause]. She deserves excellent [Applause]! [Applause]. So we can see, the GSM was busy. Not many people are making GSM calls at four in the morning.  [Applause]. 
>> We're always trying to keep the ticket prices as low as possible and make it available to as many people as possible. We always balance that versus ... . Really something we can afford, nor we would we want it, so we rely on the enormous generosity of sponsors ... I would like to give a particular shout-out this year to Sky for Business, without whom we would have no uplink at all. Our uplink circuit to a nearby town where they have a point of presence, and they take it to London for us. We had very few options there, and they were awesome.  I would also like to thank the others, who I will read out quickly ... LONAP, Babbio, and Arista. Many thanks to them. [Applause].   I also want to thank the volunteers who popped by from time to time offering to run around the dark to plug people in. We need your help again to unplug them! And beginning tomorrow, at 9 am, we begin teardown. That's all the cables. If you want to help out, come by at nine. These  these slides will be on our GitHub, and here's our Twitter. [Cheering and applause]. 
What makes processors fail - and how to prevent it by Alastair Reid
>> I've been working with processors. They are incredibly reliable. They're not completely reliable, right? They do occasionally fail, we hear about bus in processors, but it's such a rare thing that if you and I were to make a list of the processor bugs we've ever heard of, we would probably will nine out of ten things in our list would be the same. In fact, we would not even get to ten. So, I'm going to be talking about how it is that processors are actually amazingly close to being ... how do we achieve that? So, if you want a more technical version of the information in this talk, I put links in the slides, I put my links on the website afterwards. Related to this, if anyone was in Johnny Austin's workshop yesterday, where we had a bunch of humans pretending to be different parts modelling a five-stage pipeline, that was also [inaudible]. Processors always work. This is because there's a tension going on. Sorry, is there an echo in this? There's a tension going on in creating a processor. On the one hand, you want it to be correct, and, on another, you want it to be fast. These things are completely in opposition to each other. It is hard to make something correct, and so this is a talk with a villain and a hero. Bad news, the villain is, in fact, the designer. He's trying to make things faster. As he tries to do that, he inevitably introduces ... . You turned down at little bit. I'm getting a lot of echo. That could work too. The designer is busy introducing bugs, and making it go faster, too. Meanwhile, the hero is the person trying to find those bugs and help fix them. So, so the verifying is pushing back against the designer. In the commercial processor, the verifier usually wins because a fast processor is nice, but a correct process is critical. No-one is interested if it mostly works. So the verifier will win the battle over is this too complex? The verifier is helped by useful tools. They're called sat solvers and bounded model checkers. Sexy names, but ... . Okay, what I'm going to do in this talk is kind of look at this switch back and forth between correct and fast. I'm going to start with a very simple processor. So, what I've done here is taken an early mix processor, and I've simplified it down just by kind of pasting over some of the complicated  features, so it's more correct. Let me just quickly go through the main bit of the processor. Working from left to right, when you can execute instruction, you need to know which instruction you're going to execute. You take your programme counter from the green box, you hand it to the memory, and it gives you back an instruction. You then have to figure out what the instruction means, so you decode it. Traditionally, that block is shown in white in diagrams like that, so I followed that tradition. Code logic is shown in white so that you can't actually ... most complicated part of the ... always leave it out of the picture. That gives you all the control signals to control the rest of the circuit. The next bit is from the green bit in the middle, the register file, you read the input, and you hand that to the ALU which can do arithmetic. You can also pass the values through the memory if you want to read or write memory. Then when you're all done, ... go in this big backward path, back over to the register file where ... if something is corrected to the same thing, there's a good chance you will stop when you get it wrong, if you have the wrong information there. Again, little itty boxes don't look very significant. That's where a lot of bugs will occur. But anyway, we've go the our processor. It's one time step all the way round to executing the results. It's about simple as you can make the processor. Having done that, remember, the hero is the verifier, and we're wondering does it work? So, how do we check if something works? We test it. What kind of tests do we run? Well, I'm guessing most of you are more software people than hardware people but it is the same either way. If you want to check something, you do a list of all the qualities you're meant to have, the corner cases you're going to worry about, and that gives you a bunch of cases that you ought to consider testing. Once you've got that, you then decided how many tests do I want for each case? It doesn't matter of whether it works or not. Then, maybe one test for every ten cases is good enough, right? That's what I do in my hobby projects. If you're a bit more serious, maybe you want test per case, 50, 1,000, million? How much is it going to cost if it goes wrong? How hard will it be to replace it? You play around with this, and decide how much testing you want. That's the traditional way of checking the process that's right. Before we get on the less traditional, the modern way, we've got our test, now we need to think about running them. We've got a processor. We run programmes on them but how will we know if the programme did the right thing? What we're going to want is a reference that we can ... . This might be a simulator, or it might be your friend is implementing the same processor. So, he's got another implementation. He's smarter than you, so maybe he's put less bugs in it. Maybe because he's smarter than with you be he got too clever, and he put more bugs into it. Either way, you're hoping he's got different bugs. So you've got a reference to compare against, and then you can take all the individual parts of the state of the process. We can run tests through that. But running tests, there's another way using more verification [inaudible] which can be used. There are tools which will take two circuits ... to tell you whether they're equivalent to each other. In the industry, those are called logical equivalence checkers, stats ... which are a slightly more flexible investigation of this, and what these do is say particular every possible state, every possible instruction, all the contents, and then just check that these two circuits are going to do exactly the same thing, no matter what. So the beautiful thing about this is you don't have to think about testing. Right? It just tries everything. It doesn't brute-force it, that would be too hard, it uses various mathematical tricks to try to reduce the number of things it has to check but some equivalence checking for all possible inputs that these are equivalent to each other. So you don't to think of any tests which is great because I hate thinking about tests. It is just not fun, right?  So this will make up the tests for you, and think of all the other things you should have been thinking about but they are really nice tools when you can use them. Okay, so, that's us at the start of this cycle. So, we are on the end of we've got something that is correct, but possibly - so now I'm going to look at a simple optimisation which people always do to this process, to make it a bit faster. [Sound cut]. The processor kind of did ... the work in two stages. Remember, it started off by fetching an instruction and decoding it. Then, in the second phase, the second phase of execution, it's adding results, it is writing them to registers and so on, and whilst it is fetching, you don't know what the right-hand side, the ELU, the memory should be doing, so it sits idle. Once you've fetched and decoded something you can't do anything because you've got to wait until execute finishes. So designers hate this kind of thing. Hardware sitting idle, they hate that. So, standard technique is instruction pipelining. And with instruction pipe lining, what we are going to do is double the clock frequency, and then while we are executing the first instruction doing the arithmetic or memory access, we will be at the same time fetching the sending ... . While we are executing that second instruction, we will be fetching the third while we are fetching the third, get double performance. This is a technique IBM came up in the 1960s, it his microprocessors in the mid-1980s. There is this green bar down the middle. Those are pipeline registers remembering the first instruction it fetched while it is executing that, and that leads the left-hand side is now free to start fetching ... . Pipelines are a pretty common thing. And what we want to do now is check to see if we've introduced any bugs in doing this. So, how are we going to do that? Let's start with the reference circuit, so we've got our reference circuit, the processes will be executing two instructions at a time. I'm going to want to check both instructions, and so I will put in two of copies of the reference circuit ... into the start state of the next circuit. That's going - and then I'm going to do the same thing with the processor that I want to check. I'm going to make two copies of that. Again, I'm going to add in data paths so that the final state of the professor gets copied ... final and intermediate states [off mic]. Forward that that data over and then I will add the checkers. There are tools which will do it which I will mention later on, but what I have now is something where I can feed two instructions into this processor and check that they're both going to execute correctly. Again, the form of verification tools will just check for all possible pairs of instructions, all possible initial states. I don't have to come up with it. But as I say, I can also use testing, right? I can just run one processor against one reference and ... whichever one I do, it's probably not going to be very long before I run into a bug that looks a little bit like that. Instruction followed by pretty much anything. Because, that style of processor that I just showed you is prone to a bug that occurs after branch instruction s. So what goes wrong in branch instructions? Let's think about how the pipeline is going to be executing this. So, the next clock cycle, I execute the branch instruction to figure out where I should branch to. And at the same time, I'm fetching the add instruction. Then in the next cycle, everything moves forward, and I go to execute the add instruction. But why am I executing the add instruction? That branch instruction is telling me not to execute the next instruction, it's telling me to go off somewhere else and execute that instead. But what is happening I will always execute the instruction immediately after a branch. There are several ways of thinking about what has happened here. One is, and it's to say that this is a bug. A pretty common opinion these days that you are after a branch. You always execute the instruction immediately after. At the time that people started pipe lining micro processors, there was another feature - not a bug - called a "branch-delay spot". They fell out of favour later because, if you tried to claim that every single bug you put in your processor is actually a feature, then it's very hard to make the second processor have exactly the same set of bugs, and, of course, it's going to add some new bugs of its own, so your third processor becomes really hard. You've got to get the old bugs and persuade new people that bugs are features as well. People  now admit it's a bug and fix it. You get a branch instruction, you say let's hold off fetching the instruction until I know for sure if I need it. That's one solution. That's called "stalling the pipeline". Another one is to go, you know what? I'm going to go ahead and fetch it anyway. I might even start executing it a little bit. But I will only go so far in executing it. I hope nobody notices and I end up having to cancel it. You might want to execute the instruction, and, if you didn't need it, you cancel it quickly. That's called speculation which has been in the news a lot recently, this year, because it turns out that some people can spot speculation and turn it into security calls.  We added an optimisation. Various ways of testing and verifying it, and we got a bug. Having fixed that, I want to check if there is did I fix it, and what can I worry about? I've got my original tests I started off with. Does the add big numbers and small numbers? Obviously, I'm going to add a whole load of test for branches because I now know to be worried about that, but is there anything else I should be worried about in that processor? I'm going to test all of those. This is kind of black magic, experience, asking your friend who he tests, so, it's hard to know you've tested everything. That kind of emphasise, that's where the form of verification techniques are helpful because you don't have to come up with lists of pairs of instructions. I've gone through one round of this cycle. Made it broken. Find some bugs and fix it. So, that's - and I did that by going from a one-stage pipeline to a two-stage pipeline. What would be better than a two-stage pipeline? The answer for most people is a five-stage pipeline. Five stages, we take that original diagram I had, and it had about five major steps in it, and we make each of those be one major step in execution, and what I'm going to do then is have my five pipelines, each row in this diagram is busy doing one of those five steps. The idea is that once it gets up to speed, I'm executing five instructions at once. I'm working from the bottom upwards, writing back the result of the first instruction while I'm doing the memory access for the second, I'm doing the arithmetic for the third, decoding the fourth, and I'm fetching the fifth. I'm keeping all the bits of the hardware busy and this makes a designer really, really happy, and it tends to make the  verifier a bit less happy. Here's the original circuit as I downloaded it off Wikipedia with all the pipeline stages shown, so the pipeline stages are these big vertical green bars that just capture the bit that was just calculated and make it available in the next step, and what can I do to verify this? Well, got the same option as before. One copy of the reference circuit, one copy of the processor, and then add some comparison logic to just ... and then I can run all the tests I want in this. Yes, run lots of tests on it. With that, if I want to do the formal verification, then I'm going to do something similar to what I did previously when I had two copies of the reference, two copies of the processor, but I'm going to have this time a five-stage pipeline, so five copies of the referenced copies of the processor model. Five instruction s at once. Except, this may not be quite enough, because if you remember, the fix for that branch-related bug was that sometimes instructions could get stalled. If I'm stalling instructions, they may not take five cycles to get all the way down to the end of the pipeline, they may sometimes take six, so I had better add another stage. While maybe I could have two instructions get stalled, or one gets stalled twice, maybe I should add another stage. I play around with that and try to get the right number of steps that I'm checking. So, in this side, I've labelled this with its official name, called bounded-model checking. I will explain what model - the bounded bit is this number of how many copies I make. So, I started off with a bound of five, increased it to a bound of [off mic] and there are tools that will do this transfer transformation of making multiple copies. They will do it for you. There are tools I like Yoses which is open SBGA work, you will probably know about the Yoses tools. There are talks about using bounded model checking that you can get hold of. There's paper that I mentioned at the start that I wrote that you can get hold of, and blogs, there are a bunch of links there that you can follow. So, we run some tests, we do some - oh, let me just emphasise, just once more, that what is going to do is it's going to test any sequence of instructions be with up to seven instructions will get checked, and for all possible inputs, so, it's going to run through the first check, then the second, and third, and so on, and, if it manages to get all the way to the end, then you're going to know that any cycle sequence anywhere in execution is going to behave. So, you don't have to come up with your own test. So, either through testing or this bounded model checking, you will find another bug. This is another well-known bug in this style of processor. Actually fixed in the next generation of processor. The bug follows a load by a store. Let's think about what is going on when you have a load followed by a store. So I was kind of zoomed forward to the point where the load is in the memory stage, and the store is behind it in the execute stage. The load is busy, it's got abaddress, it hands that to the memory, and it reads back a value from the memory. So now you've got a value from memory. The same time that that is happening, the store has finished reading some values from the register file and it's sitting in the execute stage waiting ready to execute. Let's go forward one cycle. This point, the load writes back the value it got from memory back to the register file, and the store starts to write something to the data memory. What is it writing? Look at the programme. You might expect I store in register zero and story from register zero. You hope it's restoring the value you loaded from memory. That's not what happens. The store had already read some values from the register file before it got to that point. It's going to store the previous value from register zero. I would call this a bug, and in the next generation, the processor chose not to do this, but the first generation, they called it a feature and gave it a fancy name, "load-delay slot". They said if you do a load, then you must wait at least one instruction before you use the result of that load. So, one way of fixing it is to say programmers need to do something between the load and the store, or get the compiler to do it for them. Either way, it's not a hardware problem, not a bug, it is a feature. So now, yes, if you disagree with that, and you actually want to fix the problem, you could, as we did with the branch, and just stall the processor, wait a bit until the value has made it back to the register file and you are all good. The more common one is not to stop and try to maintain a bit of performance. The reason for that is if you think about it, at the point when I went to execute the store instruction, I had actually already successfully got a value from memory. The only problem was I had already got a value from somewhere else. There was no way that the value I had, which by this point was in the right back stage - that was grey marks on the furthest to the right-hand side - that's where the value was. If only I could get it from there into the memory, everything would be good. Let's add a data path that will do that. We add a Tait path with add another set to select which, whether to use this forwarded value, this bypassed value, or to use the value we got from registers, so, we do that, but there's two inputs to the memory? Well, maybe we should another forwarding path so that it doesn't matter whether we're using the value we read as an address or as data. Either way, it's going to work. That's good and fixed it. But, unfortunately, there's another bug. Any use of the value will break things. So, if I have a load followed by an add, that will also not work. The same fix works. Just a different data. We add another path going a bit further back. It could affect either input of the addition, so add another path. It turns out there is yet another bug which is an add immediately followed by an add. We will have the same problem. It takes ages. It takes two whole cycles for the result of an add to get all the way round to the register file and be ready for an operation. So, you can fix that by adding another forwarding path, and another forwarding path. And it's - and then, one more final bug that I could spot in this diagram, which is if we have a load, and then we branch to the address that we just loaded, you might do, you add another path. In each of these cases, if we decided it's too expensive adding another data path, we have an option of stalling in this circumstance. So for each of these potential bugs, we've got a choice of stalling or adding a forwarding path, and then we've got to make a list of all the times we want to stall, all the times we want to use a forwarding path, add in a control logic to select the right input at the right time, or to install the processor, and what we end up with is a lot of new corner and different things we need to test because there are so many different situations in which this forwarding logic is meant to trigger or not meant to trigger. Back to what tests should we be running? Well, all our single-stage tests, all our two-instruction tests, those are followed by pretty much anything because we're now scared of loads going wrong, and then how many - how long does an instruction sequence have before it's guaranteed not to have any new bugs you haven't seen in the shortest sequence? When you get four instructions to fail - I think you can get five instructions to fail, a chain of five, with the last one is the one that goes wrong. You come up with your guess how long that sequence can be and you try to figure out what would make a sequence interesting and a right test for it. Or, again, you rely on formal verification, if that is powerful enough to cope with the complexity of the design you're working on. That's me. I've now done two rounds this cycle. Something right, correct. Make it, but make it really fast. Fix it, then make it even faster, and even more broken. Fix that, and hopefully, you now have a work in - a working processor, because you've got good ways of testing it. I'm not going to iterations on processor optimisations. I'm going to think about what is happening with formal verification. What is going on here? You can think of formal verification, we start from one point and then we try all possible instructions that could happen next. And then we take another step and all possible instructions following on from that. All possible instructions that could follow on from that. Keep going like this, doing the first exploration. But if any of you have played around with - the state space here is just exploding, and eventually you're going to hit some limit where you just can't explore any deeper, right?  You've been extremely thorough in what you've checked but you just can't get any deeper because you've run out of memory, or it says it's going to take another Tait run, another week or month, whatever, to run. So, you're kind of stuck at that point. So testing is a good technique as well. I've been saying that formal verification is great but testing is good that it has this nice starting, that you can run a big long programme. I've done enough of that, I will try something else. Just keep trying different things. I'm not exploring very thoroughly, right? I'm not filling in the screen with solid blocks of colour, but I'm getting really deep, interesting complicated - at least if my tests [inaudible]. So formal verification which is red first, testing which is depth first. Really good for finding bugs. But more recently, what we've been doing is switching to our kind of mix mode where we will start off with the formal verification, seeing how deep we can get. When we reach whatever the limit is, we then ... testing but as - but then we take some of the paths we've found by testing and say let's do a little formal verification around that, and we try to broaden out around each line, so able to fill in more of the search place, get to the deep states and search around there. We keep doing that for a while, and woe gain a lot more confidence, not just that we've searched for sequences thoroughly, but we've seen a lot of  depth as well. I started off by saying that processors almost always work. I hope I gave you an a sense of why that's an amazing thing. Just going to a five-stage pipeline, things were getting, I think, kind of complicated, and the testing for them is getting complicated. So, then I talked a lot about how we go back and forth between the designer and the verifier. At the start, said the verifying tends to win the fight over how much complexity you're allowed in the processor because you want the thing to work. Using these formal verification technical  technical weeks, we can check processors more thoroughly enabling us to shift the balance over, so that the designer is able to push much harder towards what he wants to do which is to make the processor fast without making the verifying unhappy about what is going on. So, let's see. So, just in closing, I've been showing you processor designs from 1985. In order to bring it more up to date, if any of you like playing it microcontrollers, this is one of of ARM's most recent controllers, a CortexM7. Creasing it from the five stages we saw earlier, and there are five separate execution pipelines instead of just being able to do memory and arithmetic, and it can issue two instructions in parallel. Two ininstrumentations in every step. Remember, the five-stage pipeline added, six or seven forwarding paths, so nice and fast, so we wouldn't have to stall too often? Well, imagine for each pipeline, I'm going to add a number of forward ing paths - probably about for or six separate forwarding paths for each pipe line. Between pipelines, I'm going to add some forwarding paths as well. Let me give you a quick glance of what it's going to look like [Laughter]. It's quite complicated.  This is not completely unrealistic. It's really incredibly complicated, make a processor of this complexity that will be reliable, designed for embedded systems for it to work - you want it to work. So I hope I've given you a sense of what verifying processes is like and designing them. [Applause]. 
FLOOR:  Thank you very much for the talk. What methods do you use to decide when the verification is complete? When have you done your job? 
>> A whole lot of experience. The first ARM processor was designed over 30 years ago. There's 30 years of experience of just kind of like we did this much last time, happy with that or unhappy with it, or let's do more or the same. There are a whole load of people who think hard about it, obviously. There's a classic thing of measure the number of bugs, that you look at the bug curve, and as it starts to tail off, you think you're looking good, so there's a very long soak-testing period. At the end, with the formal verification, you can also say, you can try to come up with a property which, when it is true, will tell you there is nothing more interesting to find. All the instructions have made it down the pipeline, so that you go prove that that number is less than seven, and you know that seven would be the right number to use. There are a variety of techniques. You could say, I'm actually in the research group. I helped people who have developing this, work in developing this formal verification, but I'm kind of a fake, you know! The guys who actually do the verification of real processors, they are the heroes I was talking about, not me. 
FLOOR:  Do you think the recent speculative execution issues have put a greater focus on the formal verification stuff? Have you seen a shift in day-to-day [inaudible]. 
>> I think we had already reached a point where the traditional testing was kind of at its limit. It is really important a processor works. If the processor in your phone has a problem, we can't change all the software in an app store, right? It's really expensive to recall phones. They really have to work. All processor vendors ... it's really hard for [inaudible]. Pushed it a little. I've got an idea of how to use formal verification techniques ... of applying. But maybe pushed it a little but we were already there. 
FLOOR:  How many use cycles can you verify these days? 
>> It varies with which processor you're working on. So I was working on a little three and a half stage pipe, and there we get 80 cycles deep and then kill it because it was never going to find anything else. Others, when I was working in the project, would get stuck at maybe - it varies. Then again, it's more likely to have [sound cutting out] before .
FLOOR:  In your experience, has a problem got out into the wild and having analysed that problem when it's out in the real world, have you had to modify your formal verification techniques as a result, sort of what is most embarrassing incident where this has actually happened? 
>> I think we applied this - we're doing it about three years ago that we were developing this kind of, and, in that kind of tailing-off overt next year or so, so maybe about two years ago that earliest processors we did this to. Finished sparse we were concerned. It then takes another year or so for something to make ... maybe another six to 12 months for it actually to kind of in a package that you can buy. So we're about to find out, I guess. Yes. We do know it finds a lot more bugs, it finds them of earlier because the cost of fixing a bug goes up exponentially of course with the length of time that it sits. We catch bugs that we were not sure we would catch by testing. We're happy with it as a technique. I think we're still learning how to use it. 
>> Thank you very much indeed, Alistair Reid. [Applause]. 